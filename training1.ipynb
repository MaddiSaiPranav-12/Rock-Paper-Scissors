{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec274a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from CyclicGen_model import Voxel_flow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d29e14fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_triplets(triplets_txt_path):\n",
    "    with open(triplets_txt_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    triplets = [line.strip().split() for line in lines]\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f992dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "690a515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_feature_extractor():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "    output = base_model.get_layer('block4_conv3').output\n",
    "    return Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a2f9191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_voxel_flow(triplets_txt_path, batch_size, num_epochs, train_dir):\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    \n",
    "    # Load triplets\n",
    "    triplets = load_triplets(triplets_txt_path)\n",
    "    \n",
    "    # Prepare VGG feature extractor\n",
    "    vgg_model = get_vgg_feature_extractor()\n",
    "    \n",
    "    # Create Voxel Flow Model\n",
    "    voxel_model = Voxel_flow_model()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "    # Loss history\n",
    "    loss_history = []\n",
    "\n",
    "    # Epoch training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "        np.random.shuffle(triplets)\n",
    "        total_loss = 0\n",
    "\n",
    "        for i in range(0, len(triplets), batch_size):\n",
    "            batch = triplets[i:i + batch_size]\n",
    "            if len(batch) < batch_size:\n",
    "                continue  # Skip incomplete batch\n",
    "\n",
    "            # Load batch images\n",
    "            f1_batch, f2_batch, f3_batch = [], [], []\n",
    "            for f1, f2, f3 in batch:\n",
    "                f1_batch.append(load_and_preprocess_image(f1))\n",
    "                f2_batch.append(load_and_preprocess_image(f2))\n",
    "                f3_batch.append(load_and_preprocess_image(f3))\n",
    "\n",
    "            f1_batch = tf.stack(f1_batch)\n",
    "            f2_batch = tf.stack(f2_batch)\n",
    "            f3_batch = tf.stack(f3_batch)\n",
    "\n",
    "            # Extract VGG features\n",
    "            edge_1 = tf.nn.sigmoid(vgg_model(preprocess_input(f1_batch * 255.0)))\n",
    "            edge_3 = tf.nn.sigmoid(vgg_model(preprocess_input(f3_batch * 255.0)))\n",
    "\n",
    "            # Resize feature maps to match input size\n",
    "            edge_1 = tf.image.resize(edge_1, [256, 256])\n",
    "            edge_3 = tf.image.resize(edge_3, [256, 256])\n",
    "\n",
    "            # Concatenate inputs\n",
    "            input_tensor = tf.concat([f1_batch, f3_batch, edge_1, edge_3], axis=-1)\n",
    "\n",
    "            # Training step\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred_f2, _ = voxel_model.inference(input_tensor)\n",
    "                loss = tf.reduce_mean(tf.abs(pred_f2 - f2_batch))\n",
    "\n",
    "            grads = tape.gradient(loss, voxel_model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, voxel_model.trainable_variables))\n",
    "\n",
    "            total_loss += loss.numpy()\n",
    "\n",
    "        avg_loss = total_loss / (len(triplets) // batch_size)\n",
    "        loss_history.append(avg_loss)\n",
    "        print(f\"Average Loss: {avg_loss:.5f}\")\n",
    "\n",
    "        # Save model weights every epoch\n",
    "        voxel_model.save_weights(os.path.join(train_dir, f\"model_epoch_{epoch+1}.ckpt\"))\n",
    "\n",
    "    # Plot loss curve\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, num_epochs + 1), loss_history, marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('L1 Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(train_dir, \"loss_plot.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c685733",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_voxel_flow(\n",
    "    triplets_txt_path=\"D:/VFI/CyclicGen/triplets.txt\",\n",
    "    batch_size=4,\n",
    "    num_epochs=10,\n",
    "    train_dir=\"training_logs\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
